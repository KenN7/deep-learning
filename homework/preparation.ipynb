{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep leaning for computer vision: Preparation\n",
    "\n",
    "In this first homework, you will familiarize yourself with the basics of differentiable programming and the PyTorch framework.\n",
    "\n",
    "In the following, we provide some code blocks that are already running, along with explanations. You are asked to complete the code blocks in which the `# your code` comment is present. Sometimes, you will also have to motivate why you programmed certain things or guide us quickly through the results you obtained. If this is required you will see the following instruction:\n",
    "\n",
    "> your discussion\n",
    "\n",
    "Please note that you will **not** have to handle in any sort of written report by the end of the assignment. We do however expect you to submit the notebook **with the solutions** to the exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports\n",
    "\n",
    "Our first step is very easy: we simply import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tensors and basic operations\n",
    "\n",
    "Tensors are one of the main ingredients when it comes to modern deep learning frameworks. Almost all deep learning computations can be expressed as tensor operations which make computation fast and efficient, especially on graphics processing units (GPUs). We will now see how to manipulate tensors within the PyTorch framework.\n",
    "\n",
    "There are many valid definitions for tensors, but to keep it simple you can see them as multi-dimensional arrays. Zero-dimensional tensors are scalars, one-dimensional tensors are vectors, two-dimensional tensors are matrices, etc.\n",
    "\n",
    "In PyTorch, a tensor is an instance of the class `torch.Tensor`. PyTorch tensors are **very** similar to NumPy arrays.\n",
    "Almost any operations you could imagine can be performed on tensors (see [API](https://pytorch.org/docs/stable/tensors.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Tensors\n",
    "\n",
    "There are many ways to [create tensors](https://pytorch.org/docs/stable/tensors.html#torch.Tensor), for instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can create a tensor from lists\n",
    "t1 = torch.tensor([[1, 2], [-7, 9]])\n",
    "print(t1)\n",
    "\n",
    "# or from numpy arrays\n",
    "t2 = torch.from_numpy(np.array([[1., 8.], [0., 3.]]))\n",
    "print(t2)\n",
    "\n",
    "# or we can create a 2x3x4 tensor filled with zeros\n",
    "t3 = torch.zeros(2, 3, 4)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an array may contain different types of data (e.g. float, int, boolean), so can a tensor. Let's check what types of data are in `t1`, `t2` and `t3`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t1.dtype, t2.dtype, t3.dtype, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, PyTorch uses an integer data type to store integer values and a floating-point data type to store real values. However, unlike NumPy, PyTorch uses a **single-precision** floating-point data type (`float32`) by default.\n",
    "\n",
    "You can convert tensors from one type to another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t1.float(), t2.long(), t3.double(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important property of a tensor is its shape. You can use the `.shape` property or `.size()` method to check the dimensions of a tensor. Both return a `torch.Size` object that can be manipulated with its own operations. Most of the time, you will just use `torch.Size` objects as tuples or lists (e.g. to check the size of a tensor along one of its dimension)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the full shape\n",
    "print(t1.shape)\n",
    "\n",
    "# the length of the tensor along its first dimension\n",
    "print(t2.shape[0])\n",
    "\n",
    "# the shape of the two last dimensions\n",
    "print(t3.shape[-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Operations\n",
    "\n",
    "We now consider simple tensor operations on 1D (vectors) and 2D (matrices) tensors. Lets instantiate two vectors with 5 elements and two matrices of respectively 3x5 and 5x5 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = torch.ones(5)\n",
    "print(v1)\n",
    "\n",
    "v2 = torch.randn(5)  # standard gaussian\n",
    "print(v2)\n",
    "\n",
    "m1 = torch.rand(3, 5)  # [0, 1) uniform\n",
    "print(m1)\n",
    "\n",
    "m2 = torch.eye(5)  # identity matrix\n",
    "print(m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most basic operations are the addition, subtraction, multiplication and division. As in NumPy, but unlike MATLAB, the symbols `+, -, *, /` all perform **element-wise** operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add v1 and v2\n",
    "v_sum = v1 + v2\n",
    "print(v_sum)\n",
    "\n",
    "# subtract v1 from v2\n",
    "v_sub = v1 - v2\n",
    "print(v_sub)\n",
    "\n",
    "# multiply the elements of v1 and v2\n",
    "v_mul = v1 * v2\n",
    "print(v_mul)\n",
    "\n",
    "# divide the elements of v1 by v2\n",
    "v_div = v1 / v2\n",
    "print(v_div)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When trying to perform an element-wise operation between tensors of different shapes, the tensors are [broadcast](https://numpy.org/doc/stable/user/basics.broadcasting.html) together, if possible. Notably, this allows to add or multiply tensors by scalars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a scalar\n",
    "print(v1 + 1)\n",
    "\n",
    "# multiply by scalar\n",
    "print(v2 * 2)\n",
    "\n",
    "# broadcast substraction between vector and matrix\n",
    "print(v2 - m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another basic operation with tensors is the inner product, denoted by the symbol `@`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scalar product between v1 and v2\n",
    "print(v1 @ v2)\n",
    "\n",
    "# matrix-vector product between m1 and v2\n",
    "print(m1 @ v2)\n",
    "\n",
    "# matrix-matrix product between m1 and m2\n",
    "print(m1 @ m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregation\n",
    "\n",
    "Common operations are to aggregate the values of a tensor along a dimension into a single value. For instance, computing the sum of the rows of a matrix . A lot of aggregation methods such as `.sum`, `.prod`, `.mean`, `.max`, ... are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of rows of m1\n",
    "print(m1.sum(dim=1))\n",
    "\n",
    "# mean of columns of m2\n",
    "print(m2.mean(dim=0))\n",
    "\n",
    "# prod of the elements of v2\n",
    "print(v2.prod())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing\n",
    "\n",
    "Sometimes you would like to extract a sub-tensor from the tensor. This operation is called *slicing*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract elements 0 (included) to 2 (not included)\n",
    "print(v1[0:2])\n",
    "\n",
    "# extract all elements but the last\n",
    "print(v2[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may also extract a subset of the elements by passing a list of indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the first, fourth and fifth elements\n",
    "v2[[0, 3, 4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrices can also be sliced/indexed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1[:4, 2:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Squeeze and Unsqueeze\n",
    "\n",
    "Squeezing removes dimensions of size 1 from tensors. Unsqueezing adds a dimension of size 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before unsqueeze\n",
    "print(m1.shape)\n",
    "\n",
    "# after unsqueeze\n",
    "m1 = m1.unsqueeze(1)\n",
    "print(m1.shape)\n",
    "\n",
    "# after squeeze\n",
    "m1 = m1.squeeze(1)\n",
    "print(m1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View\n",
    "\n",
    "Sometimes, tensors don't have the correct shape. For example, you might want to process 3x32x32 images as vectors of 3072 elements. The `.view` method returns a new tensor with the same data, but of a different shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.rand(10, 3, 32, 32)\n",
    "print(images.shape)\n",
    "\n",
    "images_as_vectors = images.view(10, -1)\n",
    "print(images_as_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, both tensors share the same underlying data, meaning that modifying one in-place will also modify the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0, :] = torch.zeros_like(images[0])\n",
    "images_as_vectors[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be noted that slicing, indexing and squeezing operations actually create views of the tensor instead of making copies of the data. For a complete list of view operations in `torch`, see the [documentation](https://pytorch.org/docs/stable/tensor_view.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other primitives\n",
    "\n",
    "A **lot** of useful primitives are available in `torch`. Notable examples are [exp](https://pytorch.org/docs/stable/generated/torch.exp.html), [log](https://pytorch.org/docs/stable/generated/torch.log.html), [sqrt](https://pytorch.org/docs/stable/generated/torch.sqrt.html), [ceil](https://pytorch.org/docs/stable/generated/torch.ceil.html), [clamp](https://pytorch.org/docs/stable/generated/torch.expand.html), [sort](https://pytorch.org/docs/stable/generated/torch.sort.html), [argmax](https://pytorch.org/docs/stable/generated/torch.argmax.html), [stack](https://pytorch.org/docs/stable/generated/torch.stack.html), [cat](https://pytorch.org/docs/stable/generated/torch.cat.html), [where](https://pytorch.org/docs/stable/generated/torch.where.html) and so on. Always take a look at the [documentation](https://pytorch.org/docs/stable/index.html) before implementing something. And don't forget: Google is your best friend!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Try it yourself!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a tensor `samples` with $10^{5}$ i.i.d. normally (mean 5 and standard deviation 2) distributed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = # your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the first 42 elements of `samples`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the last 666 elements of `samples`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract all the elements of `samples` that have an odd index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a view of shape 10x1000x10 of `samples`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the mean of `samples` using a `for` loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the mean and standard deviation of `samples` with the appropriate PyTorch operators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you observe when you compare the running time of the two code snippets?\n",
    "\n",
    "> your discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the absolute-value ($L_1$) and Euclidean ($L_2$) norms of `samples`, without loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the first and last 13 elements of `samples` as two distinct vectors and compute their [outer product](https://en.wikipedia.org/wiki/Outer_product) matrix, without loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the diagonal of this matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trace the curve defined by the coordinates\n",
    "\n",
    "$$x(t) = 16 \\sin(t)^3$$\n",
    "\n",
    "$$y(t) = 13 \\cos(t) - 5 \\cos(2t) - 2 \\cos(3t) - \\cos(4t)$$\n",
    "\n",
    "for $t \\in [0, 2\\pi[$.\n",
    "\n",
    "You can use `np.pi` for the value of $\\pi$ and the `matplotlib` package to plot the curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Manipulation\n",
    "\n",
    "In this course we will use images to train deep learning models. We thus need to learn how to manipulate images and display in python, and pytorch.\n",
    "In torch, images are tensors, that is, arrays of numbers representing the values of each pixel of the image. For example, the shape of the tensor representing a gray-scale 256x256 pixel image is: (1x256x256). Colored images code colors using 3 channels for red, green and blue colors, thus the tensor representing a colored image of the same size would have a shape of (3x256x256).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading images\n",
    "Reading images can be done using the `PIL` library or using the `torchvision` library, we will see both ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PIL and torch vision\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "\n",
    "# Open image with PIL\n",
    "img1_numpy = np.array(Image.open('corgi.png'))\n",
    "# The image is opened as a numpy array, we transform to tensor:\n",
    "img1 = torch.from_numpy(img1_numpy)\n",
    "print(img1.dtype, img1.shape)\n",
    "\n",
    "# Open image with torchvision\n",
    "img2 = torchvision.io.read_image('corgi.png')\n",
    "print(img2.dtype, img2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to be carefull with the shape of the tensor, in pytorch, the color channels must be the first dimension, but this is not the case in numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display image\n",
    "f, ax = plt.subplots(1,2)\n",
    "\n",
    "ax[0].imshow(img1)\n",
    "\n",
    "# we transpose before display because matplotlib expects numpy format (color channels last)\n",
    "img2_t = np.transpose(img2, (1, 2, 0))\n",
    "ax[1].imshow(img2_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformations that are possible on images using pytorch are presented here: https://pytorch.org/vision/stable/transforms.html#functional-transforms\n",
    "\n",
    "Use the documentation to transform one of the images by:\n",
    "- rotating the image 90°\n",
    "- invert the colors\n",
    "\n",
    "Then display the 2 images next to each other using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders\n",
    "\n",
    "One important concept is PyTorch's dataloaders. One of the core ingredients for successfully training deep learning models is data, lots of data.\n",
    "As you can easily imagine, it is not possible to load datasets of millions of images into the memory of your machine.\n",
    "To deal with this issue (and many more of them) we can use dataloaders, a data loading utility that allows us to deal with large datasets efficiently. In what follows, you are given your first example of dataloader which will use the popular CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms, utils\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = datasets.CIFAR10(root='./data', train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explain what we just did. Thanks to PyTorch's torchvision sub-library, we just downloaded the CIFAR10 dataset on our machine. The dataset was stored in the `./data` folder and comes in two different forms thanks to the use of the `train` flag: a version that can be used as training set, and a version that can be used as testing set. These two datasets are subclasses of torch's `data.Dataset` class. We will see later what this `data.Dataset` class consists in exactly. \n",
    "\n",
    "Torchvision also allows us to define a set of image transformations which we have defined at the beginning of this cell: in this case we would like to convert our images to tensors, see the [documentation](https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.ToTensor) for an exact description of this transformation.\n",
    "\n",
    "Now that we have defined which dataset we would like to use, and the form in which we would like to have our images, we can create our first data loader. Data loaders are objects over which you can iterate and that load, transform and return mini-batches of inputs/targets at each iteration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
    "testloader = data.DataLoader(testset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def show_images(img):\n",
    "    plt.imshow(transforms.functional.to_pil_image(img))\n",
    "    plt.show()\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "show_images(utils.make_grid(images))\n",
    "print(*[classes[l] for l in labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transforms module comes also in as very handy for performing other type of data transformations: here's an example which transforms the CIFAR10 images into gray scaled images. The transformations are similar to the ones we have used on our previous image loading example. Except, here, they are automatically applied when the user iterates on the dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Grayscale(), transforms.ToTensor()])\n",
    "gray_scaled_trainset = datasets.CIFAR10(root='./data', train=True, transform=transform)\n",
    "gray_scaled_trainloader = data.DataLoader(gray_scaled_trainset, batch_size=4, shuffle=True)\n",
    "\n",
    "images, labels = next(iter(gray_scaled_trainloader))\n",
    "show_images(utils.make_grid(images))\n",
    "print(*[classes[l] for l in labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make a new dataloader that:\n",
    "- rotate the images with a random angle\n",
    "- changes the brightness or the image for a random value\n",
    "\n",
    "Use the transformations described in the [documentation](https://pytorch.org/vision/stable/transforms.html#)\n",
    "\n",
    "Display 4 images from this new loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback\n",
    "\n",
    "We will now ask you a few questions to improve the content of this homework for next years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">How long did you spend on this homework?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Did you learn something?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Do you now feel comfortable with writing simple mathematical operations (like you would do in matlab or with numpy) in PyTorch?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
